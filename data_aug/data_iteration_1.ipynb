{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Data Augmentation Iteration 1"
      ],
      "metadata": {
        "id": "FkTKAiPlQPqE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Install opendatasets"
      ],
      "metadata": {
        "id": "jQkasVYJQU0Y"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dilICAiXPViB",
        "outputId": "87bb7c63-0558-4b69-b920-1b027365c24c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting opendatasets\n",
            "  Downloading opendatasets-0.1.22-py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from opendatasets) (4.67.1)\n",
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.11/dist-packages (from opendatasets) (1.7.4.2)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from opendatasets) (8.1.8)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.11/dist-packages (from kaggle->opendatasets) (6.2.0)\n",
            "Requirement already satisfied: certifi>=14.05.14 in /usr/local/lib/python3.11/dist-packages (from kaggle->opendatasets) (2025.1.31)\n",
            "Requirement already satisfied: charset-normalizer in /usr/local/lib/python3.11/dist-packages (from kaggle->opendatasets) (3.4.1)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from kaggle->opendatasets) (3.10)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from kaggle->opendatasets) (5.29.4)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.11/dist-packages (from kaggle->opendatasets) (2.8.2)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.11/dist-packages (from kaggle->opendatasets) (8.0.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from kaggle->opendatasets) (2.32.3)\n",
            "Requirement already satisfied: setuptools>=21.0.0 in /usr/local/lib/python3.11/dist-packages (from kaggle->opendatasets) (75.2.0)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.11/dist-packages (from kaggle->opendatasets) (1.17.0)\n",
            "Requirement already satisfied: text-unidecode in /usr/local/lib/python3.11/dist-packages (from kaggle->opendatasets) (1.3)\n",
            "Requirement already satisfied: urllib3>=1.15.1 in /usr/local/lib/python3.11/dist-packages (from kaggle->opendatasets) (2.3.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.11/dist-packages (from kaggle->opendatasets) (0.5.1)\n",
            "Downloading opendatasets-0.1.22-py3-none-any.whl (15 kB)\n",
            "Installing collected packages: opendatasets\n",
            "Successfully installed opendatasets-0.1.22\n"
          ]
        }
      ],
      "source": [
        "!pip install opendatasets"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Open the dataset from Kaggle. Requires username and key, see README.md for more details"
      ],
      "metadata": {
        "id": "rrkOKhKjQZI6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import opendatasets as od\n",
        "od.download(\"https://www.kaggle.com/datasets/jonathanoheix/face-expression-recognition-dataset/data\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DGjC989gPpvu",
        "outputId": "3ab900ae-7fa0-44dd-b959-6b0cb81d685a"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Please provide your Kaggle credentials to download this dataset. Learn more: http://bit.ly/kaggle-creds\n",
            "Your Kaggle username: johnnyplays\n",
            "Your Kaggle Key: ··········\n",
            "Dataset URL: https://www.kaggle.com/datasets/jonathanoheix/face-expression-recognition-dataset\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Delete redundant image folder"
      ],
      "metadata": {
        "id": "RymP9jUBQsfR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "shutil.rmtree(\"/content/face-expression-recognition-dataset/images/images\")"
      ],
      "metadata": {
        "id": "b9jCRjRePqqY"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Establish training and testing set"
      ],
      "metadata": {
        "id": "N73ipQXRQv2x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_set = \"/content/face-expression-recognition-dataset/images/train\"\n",
        "test_set = \"/content/face-expression-recognition-dataset/images/validation\""
      ],
      "metadata": {
        "id": "xqGIJMPjPuG-"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Function to create dataframe"
      ],
      "metadata": {
        "id": "ydcC6wmlQyY9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def dataframe(direct):\n",
        "    image_paths = []\n",
        "    labels = []\n",
        "    for label in os.listdir(direct):\n",
        "        for filename in os.listdir(os.path.join(direct, label)):\n",
        "            image_paths.append(os.path.join(direct, label, filename))\n",
        "            labels.append(label)\n",
        "\n",
        "            # Check if it's an original image (not translated)\n",
        "            if not filename.endswith(\"_translated.jpg\"):\n",
        "                # Add translated version if it exists\n",
        "                translated_filename = f\"{filename[:-4]}_translated.jpg\"\n",
        "                translated_path = os.path.join(direct, label, translated_filename)\n",
        "                if os.path.exists(translated_path):\n",
        "                    image_paths.append(translated_path)\n",
        "                    labels.append(label)  # Same label as original\n",
        "\n",
        "        print(label, \"completed\")\n",
        "    return image_paths, labels"
      ],
      "metadata": {
        "id": "0Y3VaqJZP2Nn"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create dataframe for training set"
      ],
      "metadata": {
        "id": "HLJBoL5sQ225"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import os"
      ],
      "metadata": {
        "id": "nRztMTNPRbes"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train = pd.DataFrame()\n",
        "train['image'], train['label'] = dataframe(train_set)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0xgcRPSbP-_5",
        "outputId": "2877e643-6b66-4bc5-e289-2bb7d57c3771"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "neutral completed\n",
            "disgust completed\n",
            "sad completed\n",
            "fear completed\n",
            "surprise completed\n",
            "happy completed\n",
            "angry completed\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create dataframe for testing set"
      ],
      "metadata": {
        "id": "-JXp1AtnQ6GJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test = pd.DataFrame()\n",
        "test['image'], test['label'] = dataframe(test_set)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IrLsbm0gQDtw",
        "outputId": "d3c77f96-b423-4a5c-c0cb-da30423971a6"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "neutral completed\n",
            "disgust completed\n",
            "sad completed\n",
            "fear completed\n",
            "surprise completed\n",
            "happy completed\n",
            "angry completed\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Function for creating translated images for data augmentation"
      ],
      "metadata": {
        "id": "GgxhNbNEQ87g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def translate_image(image, shift_x, shift_y):\n",
        "    \"\"\"Translates an image by the given shift values.\n",
        "\n",
        "    Args:\n",
        "        image: The input image as a NumPy array.\n",
        "        shift_x: The shift in the x-direction (horizontal).\n",
        "        shift_y: The shift in the y-direction (vertical).\n",
        "\n",
        "    Returns:\n",
        "        The translated image as a NumPy array.\n",
        "    \"\"\"\n",
        "\n",
        "    M = np.float32([[1, 0, shift_x], [0, 1, shift_y]])\n",
        "    translated_image = cv2.warpAffine(image, M, (image.shape[1], image.shape[0]))\n",
        "    return translated_image"
      ],
      "metadata": {
        "id": "UnNm4fdDQKM1"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Implement the translation function on training set"
      ],
      "metadata": {
        "id": "gZcGsxl-RDsd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import cv2\n",
        "import os\n",
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "1pGVW-6aRq77"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_dir = \"/content/face-expression-recognition-dataset/images/train\"  # Update with your validation data path\n",
        "\n",
        "# Define translation parameters\n",
        "shift_range = 5  # Maximum translation in pixels (adjust as needed)\n",
        "\n",
        "for emotion_folder in os.listdir(training_dir):\n",
        "    emotion_path = os.path.join(training_dir, emotion_folder)\n",
        "    for filename in tqdm(os.listdir(emotion_path)):\n",
        "        image_path = os.path.join(emotion_path, filename)\n",
        "        image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)  # Load as grayscale\n",
        "\n",
        "        # Generate random translation values\n",
        "        shift_x = np.random.randint(-shift_range, shift_range + 1)\n",
        "        shift_y = np.random.randint(-shift_range, shift_range + 1)\n",
        "\n",
        "        # Translate the image\n",
        "        translated_image = translate_image(image, shift_x, shift_y)\n",
        "\n",
        "        # Save translated image with a new name\n",
        "        new_filename = f\"{filename[:-4]}_translated.jpg\"  # Example naming\n",
        "        new_image_path = os.path.join(emotion_path, new_filename)\n",
        "        cv2.imwrite(new_image_path, translated_image)\n",
        "\n",
        "print(\"Image translation completed.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vV_z65TvQK8Y",
        "outputId": "def62e00-28bc-461a-eebe-89c69fcac495"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4982/4982 [00:01<00:00, 3676.04it/s]\n",
            "100%|██████████| 436/436 [00:00<00:00, 3933.95it/s]\n",
            "100%|██████████| 4938/4938 [00:01<00:00, 4277.27it/s]\n",
            "100%|██████████| 4103/4103 [00:00<00:00, 4392.62it/s]\n",
            "100%|██████████| 3205/3205 [00:00<00:00, 4211.21it/s]\n",
            "100%|██████████| 7164/7164 [00:01<00:00, 4144.99it/s]\n",
            "100%|██████████| 3993/3993 [00:01<00:00, 3348.19it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image translation completed.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    }
  ]
}